![github-submission-banner](https://github.com/user-attachments/assets/a1493b84-e4e2-456e-a791-ce35ee2bcf2f)

# ğŸš€ Project Title

> ğŸš€ Zeno-AI  
> Your intelligent AI chatbot and voice assistant for instant answers, natural conversations, and hands-free productivity.

---

## ğŸ“Œ Problem Statement
 
**Problem Statement 1 - Weave AI magic with Groq**

---

## ğŸ¯ Objective

Build a creative and interactive multimodal application powered by Groq, leveraging its capabilities to solve real-world problems with a focus on user experience and innovation.

---

## ğŸ§  Team & Approach

### Team Name:

`The Hackoholics`

### Team Members:

- 1 [Pritam Mandal](https://www.linkedin.com/in/pritam-mandal-871510281?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)
- 2 [Shriharsh Nandigamwar](https://www.linkedin.com/in/shriharsh-nandigamwar-b106702b1?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)
- 3 [Harshal Patil](http://www.linkedin.com/in/harshal-patil-56a0b2293)

### Your Approach:

## Why you chose this problem:

- We believe that interacting with AI should be seamless, natural, and accessible anywhereâ€”whether you're typing, speaking, or multitasking. Many current AI assistants are either limited in functionality, locked behind apps, or struggle with real-time conversational flow. We wanted to build Zeno-AI to bridge that gap: a smart assistant that understands you instantly, responds naturally, and works hands-freeâ€”perfect for productivity, accessibility, or just casual conversation.

## Key challenges you addressed:

- Real-time Voice Interaction: Enabling smooth and fast voice input/output without lag.

- Natural Language Understanding: Making sure the assistant could handle context, follow-ups, and casual dialogue.

- Multimodal Integration: Combining text and voice interfaces while maintaining consistency in behavior.

- Cross-platform Accessibility: Ensuring Zeno-AI could run on web and mobile platforms without complex setup.

## Any pivots, brainstorms, or breakthroughs during hacking:

- Initially, we focused only on a voice interface, but during brainstorming we realized a hybrid (voice + text) interface was more flexible for users.

- We pivoted from using a basic command model to integrating a full conversational AI (LLM-backed), which improved the user experience dramatically.

- A breakthrough moment was optimizing the voice-to-text pipeline using Web Speech API and custom feedback loops to reduce latency and improve response accuracy.

- We also experimented with user personas and contextual memory, which helped Zeno-AI feel more personalized and human-like.

---

## ğŸ› ï¸ Tech Stack

### Core Technologies Used:

- Frontend: React.js, Tailwind CSS & Redux Toolkit.
- APIs: Groq API & Web Speech API.
- Hosting: Netlify.app

### Sponsor Technologies Used :

- âœ… **Groq:** _Our chatbot is built with cutting-edge features to provide a smart and seamless experience. Powered by the Grok AI API, it understands and responds to user queries with impressive accuracy. To take user interaction a step further, weâ€™ve integrated a voice assistant, allowing hands-free communication and real-time responses._


---

## âœ¨ Key Features

- âœ… 1 Grok API Integration : Get smart and context-aware answers powered by Groq AI.
- âœ… 2 Voice Assistant : Talk naturally in english and get instant voice responses from the chatbot.
- âœ… 3 UI & UX : Clean, intuitive design & Integrated Dark/Light mode toggle for better User Experience.

## ![Screenshot](./public/zenoImg/Home%20zeno.png)

## ![Screenshot](./public/zenoImg/Chat%20zeno.png)

## ![Screenshot](./public/zenoImg/Voice%20zeno.png)

## ![Screenshot](./public/zenoImg/About%20zeno.png)

---

## ğŸ“½ï¸ Demo & Deliverables

- ![Demo Video](https://drive.google.com/file/d/1w5YLO4lqDFvDHHuHesCJccbwOpIhCzeu/view?usp=sharing)


---

## âœ… Tasks & Bonus Checklist

- âœ… **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form** 
- âœ… **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)** 
- âœ… **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**



---

## ğŸ§ª How to Run the Project

### Requirements:

- Node.js
- API Keys :required Groq APIÂ key.

### Local Setup:

```bash
# Clone the repo
git clone https://github.com/Pritammandal77/Zeno-AI

# Install dependencies
cd Zeno-AI
npm install

# Start development server
npm run dev
```

---

### ğŸ§¬ Future Scope

List improvements, extensions, or follow-up features:

## ğŸ“ˆ More integrations:
- Connect Zeno-AI with productivity tools like Google Calendar, Notion, Slack, or smart home devices for a more powerful assistant experience.

## ğŸ›¡ï¸ Security enhancements:
- Implement user authentication, encrypted voice data processing, and privacy-first features to ensure secure interactions.

## ğŸŒ Localization / broader accessibility:
- Memory & Personalization
Enable Zeno-AI to remember user preferences, recurring tasks, and context across sessions for a more personalizedÂ experience.

---

### ğŸ“ Resources / Credits

## APIs & Services Used

- HACKHAZARDS API â€“ for powering Zeno-AIâ€™s conversational intelligence.

- Web Speech API â€“ for real-time voice input and text-to-speech output.

## Open Source Libraries & Tools

- React â€“ for building the frontend interface.

- Tailwind CSS â€“ for quick and responsive UI styling.

## Acknowledgements

- Huge thanks to the [HACKHAZARDS] organizers and mentors for the guidance and support.

- Inspired by projects like [Zeno-AI].

- Shout-out to the amazing dev community whose tools and docs made this possible.

---

### ğŸ Final Words

## Our Hackathon Journey

What a ride! Building Zeno-AI in just a few days was equal parts chaotic and exhilarating. From ideation to demo, it was a full-speed sprint with late-night coding sessions, voice glitches that made us laugh out loud, and moments of pure â€œah-ha!â€ breakthroughs.

## Challenges

- Getting voice and text interfaces to play nice together was tougher than expectedâ€”especially with real-time syncing.

- Debugging Web Speech API quirks at 2AM definitely tested our patience (and sense of humor).

- Managing context in conversations without confusing the AI was a tricky logic puzzle we had to keep refining.

## Learnings

- We learned how important user flow isâ€”especially when switching between voice and text. Tiny tweaks made a huge difference in usability.

- Working with AI is less about telling it what to do and more about guiding it with the right prompts and context.

- Teamwork really carried us throughâ€”everyone had moments where they hit walls, and someone else would jump in with a fresh idea or fix.

---
