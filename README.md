![github-submission-banner](https://github.com/user-attachments/assets/a1493b84-e4e2-456e-a791-ce35ee2bcf2f)

# 🚀 Project Title

> 🚀 Zeno-AI  
> Your intelligent AI chatbot and voice assistant for instant answers, natural conversations, and hands-free productivity.

---

## 📌 Problem Statement
 
**Problem Statement 1 - Weave AI magic with Groq**

---

## 🎯 Objective

Build a creative and interactive multimodal application powered by Groq, leveraging its capabilities to solve real-world problems with a focus on user experience and innovation.

---

## 🧠 Team & Approach

### Team Name:

`The Hackoholics`

### Team Members:

- 1 [Pritam Mandal](https://www.linkedin.com/in/pritam-mandal-871510281?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)
- 2 [Shriharsh Nandigamwar](https://www.linkedin.com/in/shriharsh-nandigamwar-b106702b1?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)
- 3 [Harshal Patil](http://www.linkedin.com/in/harshal-patil-56a0b2293)

### Your Approach:

## Why you chose this problem:

- We believe that interacting with AI should be seamless, natural, and accessible anywhere—whether you're typing, speaking, or multitasking. Many current AI assistants are either limited in functionality, locked behind apps, or struggle with real-time conversational flow. We wanted to build Zeno-AI to bridge that gap: a smart assistant that understands you instantly, responds naturally, and works hands-free—perfect for productivity, accessibility, or just casual conversation.

## Key challenges you addressed:

- Real-time Voice Interaction: Enabling smooth and fast voice input/output without lag.

- Natural Language Understanding: Making sure the assistant could handle context, follow-ups, and casual dialogue.

- Multimodal Integration: Combining text and voice interfaces while maintaining consistency in behavior.

- Cross-platform Accessibility: Ensuring Zeno-AI could run on web and mobile platforms without complex setup.

## Any pivots, brainstorms, or breakthroughs during hacking:

- Initially, we focused only on a voice interface, but during brainstorming we realized a hybrid (voice + text) interface was more flexible for users.

- We pivoted from using a basic command model to integrating a full conversational AI (LLM-backed), which improved the user experience dramatically.

- A breakthrough moment was optimizing the voice-to-text pipeline using Web Speech API and custom feedback loops to reduce latency and improve response accuracy.

- We also experimented with user personas and contextual memory, which helped Zeno-AI feel more personalized and human-like.

---

## 🛠️ Tech Stack

### Core Technologies Used:

- Frontend: React.js, Tailwind CSS & Redux Toolkit.
- APIs: Groq API & Web Speech API.
- Hosting: Netlify.app

### Sponsor Technologies Used :

- ✅ **Groq:** _Our chatbot is built with cutting-edge features to provide a smart and seamless experience. Powered by the Grok AI API, it understands and responds to user queries with impressive accuracy. To take user interaction a step further, we’ve integrated a voice assistant, allowing hands-free communication and real-time responses._


---

## ✨ Key Features

- ✅ 1 Grok API Integration : Get smart and context-aware answers powered by Groq AI.
- ✅ 2 Voice Assistant : Talk naturally in english and get instant voice responses from the chatbot.
- ✅ 3 UI & UX : Clean, intuitive design & Integrated Dark/Light mode toggle for better User Experience.

## ![Screenshot](./public/zenoImg/Home%20zeno.png)

## ![Screenshot](./public/zenoImg/Chat%20zeno.png)

## ![Screenshot](./public/zenoImg/Voice%20zeno.png)

## ![Screenshot](./public/zenoImg/About%20zeno.png)

---

## 📽️ Demo & Deliverables

- ![Demo Video](https://drive.google.com/file/d/1w5YLO4lqDFvDHHuHesCJccbwOpIhCzeu/view?usp=sharing)


---

## ✅ Tasks & Bonus Checklist

- ✅ **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form** 
- ✅ **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)** 
- ✅ **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**



---

## 🧪 How to Run the Project

### Requirements:

- Node.js
- API Keys :required Groq API key.

### Local Setup:

```bash
# Clone the repo
git clone https://github.com/Pritammandal77/Zeno-AI

# Install dependencies
cd Zeno-AI
npm install

# Start development server
npm run dev
```

---

### 🧬 Future Scope

List improvements, extensions, or follow-up features:

## 📈 More integrations:
- Connect Zeno-AI with productivity tools like Google Calendar, Notion, Slack, or smart home devices for a more powerful assistant experience.

## 🛡️ Security enhancements:
- Implement user authentication, encrypted voice data processing, and privacy-first features to ensure secure interactions.

## 🌐 Localization / broader accessibility:
- Memory & Personalization
Enable Zeno-AI to remember user preferences, recurring tasks, and context across sessions for a more personalized experience.

---

### 📎 Resources / Credits

## APIs & Services Used

- HACKHAZARDS API – for powering Zeno-AI’s conversational intelligence.

- Web Speech API – for real-time voice input and text-to-speech output.

## Open Source Libraries & Tools

- React – for building the frontend interface.

- Tailwind CSS – for quick and responsive UI styling.

## Acknowledgements

- Huge thanks to the [HACKHAZARDS] organizers and mentors for the guidance and support.

- Inspired by projects like [Zeno-AI].

- Shout-out to the amazing dev community whose tools and docs made this possible.

---

### 🏁 Final Words

## Our Hackathon Journey

What a ride! Building Zeno-AI in just a few days was equal parts chaotic and exhilarating. From ideation to demo, it was a full-speed sprint with late-night coding sessions, voice glitches that made us laugh out loud, and moments of pure “ah-ha!” breakthroughs.

## Challenges

- Getting voice and text interfaces to play nice together was tougher than expected—especially with real-time syncing.

- Debugging Web Speech API quirks at 2AM definitely tested our patience (and sense of humor).

- Managing context in conversations without confusing the AI was a tricky logic puzzle we had to keep refining.

## Learnings

- We learned how important user flow is—especially when switching between voice and text. Tiny tweaks made a huge difference in usability.

- Working with AI is less about telling it what to do and more about guiding it with the right prompts and context.

- Teamwork really carried us through—everyone had moments where they hit walls, and someone else would jump in with a fresh idea or fix.

---
